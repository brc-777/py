import numpy as np

# Activation function: Sigmoid
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivative of sigmoid (optional, for learning)
def sigmoid_derivative(x):
    return x * (1 - x)

# Input data (XOR problem)
X = np.array([[0,0],
              [0,1],
              [1,0],
              [1,1]])

# Target output
y = np.array([[0],
              [1],
              [1],
              [0]])

# Network architecture
input_size = 2
hidden_size = 2
output_size = 1

# Random weights initialization
np.random.seed(42)
W1 = np.random.randn(input_size, hidden_size)
b1 = np.random.randn(1, hidden_size)
W2 = np.random.randn(hidden_size, output_size)
b2 = np.random.randn(1, output_size)

# Forward propagation
# Hidden layer
Z1 = np.dot(X, W1) + b1
A1 = sigmoid(Z1)

# Output layer
Z2 = np.dot(A1, W2) + b2
A2 = sigmoid(Z2)

print("Input:\n", X)
print("\nHidden layer output:\n", A1)
print("\nNetwork output:\n", A2)
